{"cells":[{"cell_type":"markdown","metadata":{"id":"LJrKCbjZsqpo"},"source":["# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"]},{"cell_type":"markdown","metadata":{"id":"V-DU0hkyVyPi"},"source":["# <font color=\"#003660\">Session 1: Introduction to Natural Language Processing</font>"]},{"cell_type":"markdown","metadata":{"id":"mhy42GjRV3ON"},"source":["# <font color=\"#003660\">Notebook 2: Binary Classification</font>\n","\n","<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n","\n","<p>\n","<center>\n","<div>\n","    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n","        ... transform raw text into a term-document matrix, <br>\n","        ... train a binary classifier on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n","    </font>\n","</div>\n","</center>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"C6vVpwIFsqps"},"source":["# Import packages\n","\n","As always, we first need to load a number of required Python packages:\n","- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n","- `SQLAlchemy`, together with `pymysql`, allows to communicate with SQL databases.\n","- `getpass` provides function to safely enter passwords.\n","- `spacy` offers industrial-strength natural language processing.\n","- `sklearn` is the de-facto standard machine learning package in Python."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"mMrhkr83sqpt"},"outputs":[],"source":["import pandas as pd\n","import spacy\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"jZd82t53sqpu"},"source":["# Load documents"]},{"cell_type":"markdown","metadata":{"id":"IsrCafxksqpv"},"source":["Load wine reviews (Source: https://www.kaggle.com/datasets/zynicide/wine-reviews) from a csv file."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["corpus = pd.read_csv('winemag-data-130k-v2.csv')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# rename Unnamed: 0 into index\n","corpus.rename(columns = {'Unnamed: 0':'index'}, inplace = True)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666269247369,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"bMzZ9re_yY5K","outputId":"7f61bd27-df93-4057-eff7-f63684e6fc72"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>country</th>\n","      <th>description</th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>province</th>\n","      <th>region_1</th>\n","      <th>region_2</th>\n","      <th>taster_name</th>\n","      <th>taster_twitter_handle</th>\n","      <th>title</th>\n","      <th>variety</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Italy</td>\n","      <td>Aromas include tropical fruit, broom, brimston...</td>\n","      <td>Vulkà Bianco</td>\n","      <td>87</td>\n","      <td>NaN</td>\n","      <td>Sicily &amp; Sardinia</td>\n","      <td>Etna</td>\n","      <td>NaN</td>\n","      <td>Kerin O’Keefe</td>\n","      <td>@kerinokeefe</td>\n","      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n","      <td>White Blend</td>\n","      <td>Nicosia</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Portugal</td>\n","      <td>This is ripe and fruity, a wine that is smooth...</td>\n","      <td>Avidagos</td>\n","      <td>87</td>\n","      <td>15.0</td>\n","      <td>Douro</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Roger Voss</td>\n","      <td>@vossroger</td>\n","      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n","      <td>Portuguese Red</td>\n","      <td>Quinta dos Avidagos</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>US</td>\n","      <td>Tart and snappy, the flavors of lime flesh and...</td>\n","      <td>NaN</td>\n","      <td>87</td>\n","      <td>14.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Willamette Valley</td>\n","      <td>Paul Gregutt</td>\n","      <td>@paulgwine</td>\n","      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n","      <td>Pinot Gris</td>\n","      <td>Rainstorm</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>US</td>\n","      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n","      <td>Reserve Late Harvest</td>\n","      <td>87</td>\n","      <td>13.0</td>\n","      <td>Michigan</td>\n","      <td>Lake Michigan Shore</td>\n","      <td>NaN</td>\n","      <td>Alexander Peartree</td>\n","      <td>NaN</td>\n","      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n","      <td>Riesling</td>\n","      <td>St. Julian</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>US</td>\n","      <td>Much like the regular bottling from 2012, this...</td>\n","      <td>Vintner's Reserve Wild Child Block</td>\n","      <td>87</td>\n","      <td>65.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Willamette Valley</td>\n","      <td>Paul Gregutt</td>\n","      <td>@paulgwine</td>\n","      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n","      <td>Pinot Noir</td>\n","      <td>Sweet Cheeks</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index   country                                        description  \\\n","0      0     Italy  Aromas include tropical fruit, broom, brimston...   \n","1      1  Portugal  This is ripe and fruity, a wine that is smooth...   \n","2      2        US  Tart and snappy, the flavors of lime flesh and...   \n","3      3        US  Pineapple rind, lemon pith and orange blossom ...   \n","4      4        US  Much like the regular bottling from 2012, this...   \n","\n","                          designation  points  price           province  \\\n","0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n","1                            Avidagos      87   15.0              Douro   \n","2                                 NaN      87   14.0             Oregon   \n","3                Reserve Late Harvest      87   13.0           Michigan   \n","4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n","\n","              region_1           region_2         taster_name  \\\n","0                 Etna                NaN       Kerin O’Keefe   \n","1                  NaN                NaN          Roger Voss   \n","2    Willamette Valley  Willamette Valley        Paul Gregutt   \n","3  Lake Michigan Shore                NaN  Alexander Peartree   \n","4    Willamette Valley  Willamette Valley        Paul Gregutt   \n","\n","  taster_twitter_handle                                              title  \\\n","0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n","1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n","2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n","3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n","4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n","\n","          variety               winery  \n","0     White Blend              Nicosia  \n","1  Portuguese Red  Quinta dos Avidagos  \n","2      Pinot Gris            Rainstorm  \n","3        Riesling           St. Julian  \n","4      Pinot Noir         Sweet Cheeks  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["corpus.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1666269247689,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"7NsIQrLiSEak","outputId":"274be739-6a25-448e-a0d2-8702bb598576"},"outputs":[{"data":{"text/plain":["(129971, 14)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["corpus.shape"]},{"cell_type":"markdown","metadata":{"id":"1v8oiPAcsqpx"},"source":["# Preprocess documents"]},{"cell_type":"markdown","metadata":{},"source":["Create response variable."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["corpus[\"verygood\"] = 0\n","corpus.loc[corpus['points'] > 90, 'verygood'] = 1"]},{"cell_type":"markdown","metadata":{"id":"7psnR5cmQLBx"},"source":["Split data into training, validation, and test set."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"uSObnTaWdgdM"},"outputs":[],"source":["training = corpus.iloc[0:80000,]\n","validation = corpus.iloc[80000:100000,]\n","test = corpus.iloc[100000:,]"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666269440366,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"m05pjMr8Rvxs","outputId":"aeed0594-90ff-4fe2-9362-462b8874376f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(80000, 15)\n","(20000, 15)\n","(29971, 15)\n"]}],"source":["print(training.shape)\n","print(validation.shape)\n","print(test.shape)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# write test to csv file\n","test[[\"index\", \"verygood\"]].to_csv('solution.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"bSrHVdoZsqpy"},"source":["Perform standard NLP preprocessing steps on the training set using spaCy. To speed up things, we disable some components of spaCy's standard NLP pipeline."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"sh4KVmP6sqpy"},"outputs":[],"source":["# YOUR CODE GOES HERE!\n","nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n"," \n","def spacy_prep_df(corpus):\n","  corpus = corpus.to_dict(\"records\")\n","  for i, entry in enumerate(corpus):\n","    doc = nlp(entry[u\"description\"])\n","    tokens_to_keep = []\n","    for token in doc:\n","      if token.is_alpha and not token.is_stop:\n","        tokens_to_keep.append(token.lemma_.lower())\n","    entry[u\"description_prep\"] = \" \".join(tokens_to_keep)\n","  corpus = pd.DataFrame(corpus)\n","  return(corpus)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"I4rKCZRs9tlj"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mspacy_prep_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mspacy_prep_df\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m      5\u001b[0m corpus \u001b[38;5;241m=\u001b[39m corpus\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(corpus):\n\u001b[0;32m----> 7\u001b[0m   doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   tokens_to_keep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/amlta/lib/python3.10/site-packages/thinc/layers/maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[0;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[1;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["training = spacy_prep_df(training)"]},{"cell_type":"markdown","metadata":{"id":"9Tothp_Ssqpz"},"source":["Display the first couple of lines of the preprocessed descriptions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1666270637484,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"UyLoiearsqpz","outputId":"c1a8fffa-cc0b-4120-b14a-b1784806d981"},"outputs":[],"source":["training[\"description_prep\"].head()"]},{"cell_type":"markdown","metadata":{"id":"QYQppmeBQUtX"},"source":["# Vectorize documents"]},{"cell_type":"markdown","metadata":{"id":"uAXDnM1Hsqp1"},"source":["Vectorization is the process of turning a collection of text documents into numerical feature vectors.\n","\n","We will use the **Bag of Words (BoW)** model for vectorization. In the BoW model, a corpus of documents is represented by a matrix with one row per document and one column per word occurring in the corpus. The cell values will either be simple frequency counts (How often does a word appear in a document?), or the term frequency (tf) times the inverse document frequency (idf) of a term. The idea of tf-idf is to scale down the impact of words that occur very frequently in a given corpus and that are therefore less informative than features that occur only in a small fraction of the corpus. Note that the BoW model completely ignores information about the position and sequences of the words in the document.\n","\n","In `sklearn`, the [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) creates a term-document matrix with (normalized) term frequencies and the [`TfIdfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) creates a term-document matrix with tf-idf weighting."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"WbeTq9S9sqp1"},"outputs":[],"source":["count_vect = CountVectorizer(min_df=10)"]},{"cell_type":"markdown","metadata":{"id":"06DEGrExsqp1"},"source":["Apply the CountVectorizer object to the review texts of the training set."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"AemriJOAsqp1"},"outputs":[],"source":["X_training = count_vect.fit_transform(training[\"description_prep\"].tolist())"]},{"cell_type":"markdown","metadata":{"id":"1OV17A_2sqp2"},"source":["Display an extract of the generated term-document matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1666270941802,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"vLq7fYBy3J2q","outputId":"031fef17-71e1-4d99-c36a-dd48939fa6ed"},"outputs":[],"source":["X_training.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1666270948540,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"ANQd_dVlsqp2","outputId":"639aa9c4-08fc-46ab-a637-2ad950e9b8b3"},"outputs":[],"source":["X_training[0:20,0:20].todense()"]},{"cell_type":"markdown","metadata":{"id":"7QTlJ4BDsqp3"},"source":["Store the labels that we want to predict in a separate variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1666271013159,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"gUpaU5Pgsqp3","outputId":"245d8d8c-e92f-4cc8-d350-eb81413ab6b9"},"outputs":[],"source":["y_training = training[\"verygood\"]\n","y_training.describe()"]},{"cell_type":"markdown","metadata":{"id":"biwWaNjNsqp4"},"source":["# Train classifier on training set"]},{"cell_type":"markdown","metadata":{"id":"WTHaUsAosqp4"},"source":["Fit a logistic regression classification with the term-document matrix as the features and the wine quality (i.e., `verygood` variable) as the label."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"YZkAh7oesqp4"},"outputs":[],"source":["clf = LogisticRegression(max_iter=1000).fit(X_training, y_training)"]},{"cell_type":"markdown","metadata":{"id":"tuAVWgC8sqp4"},"source":["Test whether classifier is working by predicting the quality of a short fake review. We apply the same NLP preprocessing steps and reuse the `count_vect` object to generate features in the same way as we did for the training set."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WrjU4Uj4-jpx"},"outputs":[],"source":["doc_new = {'index': [1],\n","           'description': ['This is a spectacular, magnificent, and majestic wine. Awesome!']}\n","\n","doc_new_df = pd.DataFrame.from_dict(doc_new)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666271286359,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"_B16iOiWsqp5","outputId":"977e054f-0750-4753-d04f-2d9aa4dfb19c"},"outputs":[],"source":["doc_new_df_prep = spacy_prep_df(doc_new_df)\n","doc_new_df_prep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666271286359,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"6sD7SeyD4nig","outputId":"0de40203-fd29-4095-80dd-03d5bbbeacc2"},"outputs":[],"source":["X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n","predicted = clf.predict(X_new)\n","predicted"]},{"cell_type":"markdown","metadata":{"id":"n6zZzlq4sqp5"},"source":["Instead of predicting binary labels, we can also predict probabilities of the classes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666271289647,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"Ks6yRPyEsqp5","outputId":"5c9b30c2-c5f8-48d4-c53a-7c7bd4e20e21"},"outputs":[],"source":["predicted_prob = clf.predict_proba(X_new)\n","print(clf.classes_)\n","print(predicted_prob)"]},{"cell_type":"markdown","metadata":{"id":"663LU5XQsqp5"},"source":["# Evaluate accuracy on validation set"]},{"cell_type":"markdown","metadata":{"id":"K8-z8rqVsqp6"},"source":["Before trying to predict the labels for the official test set, we evaluate the predictive accurcay of our model on the validation set. Again, we apply the same NLP preprocessing steps, reuse the `count_vect` object, and store `X` and `y` in separate data structures."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"mCZDzJOR51SZ"},"outputs":[],"source":["validation = spacy_prep_df(validation)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"eiUIhoK0sqp6"},"outputs":[],"source":["X_validation = count_vect.transform(validation[\"description_prep\"])\n","y_validation = validation[\"verygood\"]"]},{"cell_type":"markdown","metadata":{"id":"4upAshmAsqp6"},"source":["Call the predict function of our model with the validation data and calculate precision, recall and F1-score."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666271420302,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"3Ngkprkgsqp6","outputId":"2713b37d-c8e3-4c95-f9ee-39e2eef82b4f"},"outputs":[],"source":["predictions_validation = clf.predict(X_validation)\n","print(metrics.classification_report(y_validation, predictions_validation))"]},{"cell_type":"markdown","metadata":{"id":"sOCv-dHNsqp6"},"source":["# Interpret model"]},{"cell_type":"markdown","metadata":{"id":"oB06C4vFsqp7"},"source":["Logistic regression is typically not the most accurate classification model, but one big advantage is that it can be interpreted by looking at the coefficients of the input features."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"EOHsVlNGsqp7"},"outputs":[],"source":["coeffs = clf.coef_[0].tolist()\n","words = count_vect.get_feature_names_out()\n","words_with_coeffs = pd.DataFrame(coeffs, words, columns=[\"coeff\"])"]},{"cell_type":"markdown","metadata":{"id":"gaHsYC1xsqp7"},"source":["These are the words with the most *negative* impact.    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1666271501133,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"uc6X4kaFsqp7","outputId":"cc0ded9c-0c54-4958-e6eb-d4a2345780d3"},"outputs":[],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=True).head(10)"]},{"cell_type":"markdown","metadata":{"id":"xo2Zz0qrsqp8"},"source":["And these are the words with the most *positive* impact."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1666271540487,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"FBYjvIJnsqp8","outputId":"5d850670-4b10-424b-d12c-24364131d792"},"outputs":[],"source":["words_with_coeffs.sort_values(\"coeff\", ascending=False).head(10)"]},{"cell_type":"markdown","metadata":{"id":"EK-kUHvqUT7H"},"source":["# Make predictions on test set"]},{"cell_type":"markdown","metadata":{"id":"KOAiyw6_5ZJn"},"source":["Preprocess and vectorize the review texts of the test set."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"ljCV8CjF5m-B"},"outputs":[],"source":["test = spacy_prep_df(test)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"GKxkVjlsUXCQ"},"outputs":[],"source":["X_test = count_vect.transform(test[\"description_prep\"])\n","predictions_test = clf.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"VnUWSu8N5oZN"},"source":["Create a dataframe with the indices and predictions and save it as a CSV file (which we can upload to Kaggle)."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"dTBW2SnMUkjm"},"outputs":[],"source":["my_submission = pd.DataFrame({'index': test[\"index\"],\n","                              'verygood': predictions_test})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666271767446,"user":{"displayName":"Oliver Mueller","userId":"12717968064814035358"},"user_tz":-120},"id":"VKwZ8MIcVAjl","outputId":"7b430a7d-e926-4506-9b38-4fe94f1f658f"},"outputs":[],"source":["my_submission.head()"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"EzQ2NzHyVvGB"},"outputs":[],"source":["my_submission.to_csv(\"my_submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"4NHp_iYqX2Ob"},"source":["# Define a pipeline and tune the model"]},{"cell_type":"markdown","metadata":{"id":"JW59HxdX60bd"},"source":["Typically, we want to try out different preprocessing strategies and/or different classification algorithms. The concept of a **pipeline** in `sklearn` is very usuful to streamline this process.\n","\n","The purpose of a pipeline is to bundle several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a `__`, as in the example below."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"nGl_loPlZjJz"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf_pipe = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('clf', RandomForestClassifier()),\n","])"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"bydgFnF9ZjFc"},"outputs":[],"source":["parameters = {\n","    'vect__min_df': (10,100)\n","}"]},{"cell_type":"markdown","metadata":{"id":"Vlvsvhdp7Ty0"},"source":["With the pipeline and its parameters, it is possible to run an exhaustive search of the best parameters on a grid of possible values and evaluate their effects on the predictive accuracy using k-fold cross validation."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"zM1CqR7wZrEb"},"outputs":[],"source":["clf_pipe_gs = GridSearchCV(clf_pipe, parameters, cv=3, scoring=\"f1_macro\", n_jobs=-1)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"u-iyvUPMZuw_"},"outputs":[],"source":["clf_pipe_gs = clf_pipe_gs.fit(training[\"description_prep\"], training[\"verygood\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-wgKe0FabXj"},"outputs":[],"source":["pd.DataFrame(clf_pipe_gs.cv_results_)"]},{"cell_type":"markdown","metadata":{"id":"SaeEi9Wd773N"},"source":["After the grid search has been performed and the best parameter values have been determined, we can use the fitted pipeline object just like a normal model (e.g., call the predict method with new data)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcdAFAMgaFot"},"outputs":[],"source":["predictions_validation = clf_pipe_gs.predict(validation[\"description_prep\"])\n","print(metrics.classification_report(validation[\"verygood\"], predictions_validation))"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"uu2VTatR9DuV"},"outputs":[],"source":["predictions_test = clf_pipe_gs.predict(test[\"description_prep\"])\n","my_submission = pd.DataFrame({'index': test[\"index\"],\n","                              'verygood':predictions_test})\n","my_submission.to_csv(\"my_submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"aFi7MHRIX5v7"},"source":["For more tips and tricks on parameter tuning using grid search for text data, see: [https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
