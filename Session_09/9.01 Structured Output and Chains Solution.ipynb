{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAu-kSJo_wBW"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkW_65l0_wBX"
      },
      "source": [
        "# <font color=\"#003660\">Session 9: LLM-based Apps with LangChain</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2TLZqw4_wBX"
      },
      "source": [
        "# <font color=\"#003660\">Structured Outputs and Chains</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
        "        ... will know how to implement structured outputs in LLMs. <br>\n",
        "        ... will know how apply this to solve a real-world task in LangChain.\n",
        "    </font>\n",
        "</div>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jCXZI28fEN0"
      },
      "source": [
        "The following content is heavily inspired by the following excellent sources:\n",
        "\n",
        "* [LangChain Academy](https://academy.langchain.com/)\n",
        "* [LangChain Docs (Python)](https://python.langchain.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb8FCaO3fEN0",
        "outputId": "c3de8b19-0ed7-4bba-88db-29e2c6d1adfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.0.17-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pymupdf>=1.24.10 (from pymupdf4llm)\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading pymupdf4llm-0.0.17-py3-none-any.whl (26 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: xxhash, python-dotenv, pymupdf, mypy-extensions, marshmallow, httpx-sse, fsspec, dill, typing-inspect, pymupdf4llm, multiprocess, pydantic-settings, dataclasses-json, bitsandbytes, transformers, datasets, langchain-huggingface, langchain-community\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.0 dataclasses-json-0.6.7 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 httpx-sse-0.4.0 langchain-community-0.3.14 langchain-huggingface-0.1.2 marshmallow-3.25.1 multiprocess-0.70.16 mypy-extensions-1.0.0 pydantic-settings-2.7.1 pymupdf-1.25.1 pymupdf4llm-0.0.17 python-dotenv-1.0.1 transformers-4.48.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pymupdf4llm datasets transformers accelerate bitsandbytes langchain langchain-community langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ceIegjtfEN0"
      },
      "source": [
        "# Computer Scientists and JSON: A Love Story Written in Brackets\n",
        "\n",
        "[JSON (JavaScript Object Notation)](https://www.json.org/json-en.html) is usually loved and hated by computer scientists. But this format is especially important in the online applications and databases such as [MongoDB](https://www.mongodb.com/de-de). Therefore, LLMs are often applied to extract JSON notation from unstructured text [Liu et al. (2024)](https://doi.org/10.1145/3613905.3650756).\n",
        "\n",
        "Let's try this by prompting the model as we learned it in Session 06."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DDqf0AsEBqn"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, set_seed\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"mps:0\" if torch.mps.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the a model directly in HuggingFace we can simply use the HuggingFace [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)."
      ],
      "metadata": {
        "id": "1Ei2CjINXJzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sTx1W9OnjTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd37c62-a0a4-42d9-c944-a6e6e10986a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# generate a LangChain pipeline\n",
        "LLM_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    return_full_text=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the `pipe` cannot work easily with the LangChain `invoke` command, we need to use the LangChain `HuggingFacePipeline` wrapper."
      ],
      "metadata": {
        "id": "wxC8PV0OXaxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "Kc5_GTB5XZ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us add a simple structure prompt for the JSON-format."
      ],
      "metadata": {
        "id": "zoilryf3XuGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4o7TduFfEN1"
      },
      "outputs": [],
      "source": [
        "INSTRUCTION = \"\"\"\n",
        "Use the following json format for the answer:\n",
        "{\n",
        "    \"setup\":\"<The setup of your joke>\",\n",
        "    \"punchline\":\"<The punchline to your joke>\",\n",
        "    \"rating\":\"<Optional rating of how funny your joke is, from 1 to 10>\"\n",
        "}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us generate a Joke about cats (yes, I could`nt get a better example), because we want to store it in a MongoDB."
      ],
      "metadata": {
        "id": "vNf9XAayX3vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNabAbrTfEN1",
        "outputId": "8286146e-231b-4c36-f1d5-582dd49e6313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " {\n",
            "    \"setup\":\"Why did the cat refuse to play hide and seek? \", \n",
            "    \"punchline\":\"Because it was afraid of being 'cat'ed! \", \n",
            "    \"rating\":8\n",
            "} \n",
            "\n",
            "This joke plays on the word \"cat\" as both a noun (the animal) and an adjective (sneaky or cunning). It's a simple yet clever pun that many people find amusing. The rating of 8 indicates that while it may not be the funniest joke you've ever heard, it still manages to get a good laugh from most people.\n"
          ]
        }
      ],
      "source": [
        "set_seed(1)\n",
        "prompt = \"Tell me a joke about cats\"\n",
        "hopefully_json_response = hf.invoke(prompt + INSTRUCTION)\n",
        "print(hopefully_json_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good (not really funny) but will need some postprocessing to get only the JSON. Possibly we could do fine-tuning to improve that [Escarda-Fernández et al. (2024)](https://ceur-ws.org/Vol-3729/d3_rev.pdf), but usually we want to run this out of the box.\n",
        "\n",
        "A simple way to do this are [OutputParsers](https://python.langchain.com/docs/how_to/#output-parsers). In our case we will use the [`PyDanticOutputParser`](https://python.langchain.com/docs/how_to/output_parser_structured/), as it can also output dictionary formats for python."
      ],
      "metadata": {
        "id": "_DhEZBG7YIog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the PyDantic Model\n",
        "class Joke(BaseModel):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: str = Field(description=\"The setup of the joke\")\n",
        "    punchline: str = Field(description=\"The punchline to the joke\")\n",
        "    rating: Optional[int] = Field(\n",
        "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EcwV-r6zaw2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a parser\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)"
      ],
      "metadata": {
        "id": "K8p_wMY4a0gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlo7cKBjfEN1"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain\n",
        "chain = prompt | hf | parser"
      ],
      "metadata": {
        "id": "u0y7GMpMa7fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYR3JUAKfEN1",
        "outputId": "1dec4622-8214-4aa3-d678-c72b563374b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup='Imagine two people are arguing over which animal makes the best pet.' punchline='They both end up agreeing on one thing!' rating=7\n"
          ]
        }
      ],
      "source": [
        "set_seed(1)\n",
        "prompt = \"Tell me a joke about cats\"\n",
        "pydantic_response = chain.invoke({\"query\": prompt})\n",
        "print(pydantic_response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pydantic_response.model_dump(), type(pydantic_response.model_dump()))\n",
        "print(pydantic_response.model_dump_json(), type(pydantic_response.model_dump_json()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx7lTrz-hRGb",
        "outputId": "3efbdd54-e26d-4bff-bb95-f3472f305d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'setup': 'Imagine two people are arguing over which animal makes the best pet.', 'punchline': 'They both end up agreeing on one thing!', 'rating': 7} <class 'dict'>\n",
            "{\"setup\":\"Imagine two people are arguing over which animal makes the best pet.\",\"punchline\":\"They both end up agreeing on one thing!\",\"rating\":7} <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "tdOpM4Sprfa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Task"
      ],
      "metadata": {
        "id": "7inUJqKfn-91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise Description:**\n",
        "\n",
        "You are tasked with creating a system that extracts structured information from semi-structured text data describing swim training drills. Your goal is to transform the input into a structured JSON dictionary format that adheres to a predefined schema. This exercise requires you to design a system prompt for an AI model and implement Python classes using Pydantic to validate the extracted data.\n",
        "\n",
        "### Requirements:\n",
        "\n",
        "1. **System Prompt Design**:\n",
        "   - Design a system prompt for an AI model that clearly explains the task of extracting swim training data.\n",
        "   - Ensure the prompt outlines how to identify key components in the input data and map them to a structured JSON format.\n",
        "\n",
        "2. **Key Input Entities to Extract**:\n",
        "   - **Drill-Level Information**:\n",
        "     - `set_repetitions` (e.g., 4x, 8x, default to 1 if absent)\n",
        "     - `set_distance` (e.g., 100, 200, ...)\n",
        "     - `set_instructions` (a combination of specific swim styles and techniques, default to `\"\"` if absent)\n",
        "     - `form` (e.g., A, B, G, T)\n",
        "     - `intensity` (e.g., 1-4)\n",
        "     - `total_distance` (total meters)\n",
        "     - `total_duration` (total minutes)\n",
        "     - An optional `rest_period` in seconds (default to 0 if absent)\n",
        "   - **Set-Level Information**:\n",
        "     - A collection of **Segments** with:\n",
        "       - `distance` in meters\n",
        "       - `instructions` Ges, Arme, Beine, Tü, K, R, S, Br, Lg, S Beine, K Beine, K Arme, K Beine, RK, Lgf, Lg25, SK, BrK, Torpedo, butterfly, freestyle, CU, Reißv, LongDog, Hundepd, Entenpd, Kombi, Kontrast, DPS, EBV, AT, HB, Fb, FS, BH, Ff, Pb, SN, Brett, PT, Kanal, PK\n",
        "\n",
        "     \n",
        "3. **Output Structure**:\n",
        "   - Use a JSON dictionary format for the output, ensuring it aligns with the predefined schema.\n",
        "\n",
        "4. **Implementation with Pydantic**:\n",
        "   - Implement two classes:\n",
        "     - **Segment**: Represents a single segment of the drill, including the distance and instructions.\n",
        "     - **Drill**: Represents the overall drill, containing metadata and a list of segments.\n",
        "\n",
        "5. **Task Deliverables**:\n",
        "   - Develop a clear and concise system prompt that can instruct an AI assistant to extract the required entities from semi-structured text input.\n",
        "   - Implement the **Segment** and **Drill** classes using Pydantic to validate the extracted data."
      ],
      "metadata": {
        "id": "Xz9608tft3q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`\"4x100 FB: 25 butterfly, 50 torpedo, 25 freestyle; A2; 400 m; 8 min\"`\n",
        "\n",
        "should be processed to\n",
        "\n",
        "```\n",
        "{\n",
        "    \"total_distance\": 400,\n",
        "    \"total_duration\": 8,\n",
        "    \"form\": \"A\",\n",
        "    \"intensity\": 2,\n",
        "    \"set_repetitions\": 4,\n",
        "    \"set_distance\": 100,\n",
        "    \"set_instructions\": \"FB\",\n",
        "    \"set\": [\n",
        "        {\n",
        "            \"distance\": 25,\n",
        "            \"instructions\": \"butterfly\"\n",
        "        },\n",
        "        {\n",
        "            \"distance\": 50,\n",
        "            \"instructions\": \"torpedo\"\n",
        "        },\n",
        "        {\n",
        "            \"distance\": 25,\n",
        "            \"instructions\": \"freestyle\"\n",
        "        }\n",
        "    ],\n",
        "    \"rest_period\": 0\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DHcfCMOHvPOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packages\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, set_seed\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"mps:0\" if torch.mps.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "KUaprw7IcK-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a LangChain pipeline\n",
        "LLM_NAME = \"Qwen/Qwen2.5-7B-Instruct\" # you will need a 7B model here.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_NAME,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    return_full_text=False,\n",
        ")\n",
        "\n",
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "320f23446eba4e8889148aaae755ceb0",
            "825bedb8681f4c0f8e6f9f3bf6e23732",
            "46006bd3b9d34be48a6277d27c1d21a2",
            "077894f810a44206ae6165318fcbad9b",
            "8e2924c80e5e41d8b13eb7c94e8a33a5",
            "364616f1ffb944238c97fb5a58ddfa6b",
            "1c9b3ec072e9476295b7c46a232a913f",
            "39a57db8e76c4dc38211270d8914005a",
            "f3e840ce149a4c0b873c8698a8efc410",
            "7b2b7c67e7864b058b2853615f01d111",
            "625ad29ae9884d38a5b2809d296bcc4b"
          ]
        },
        "id": "yCA2F1bFcXlX",
        "outputId": "73ae4292-13f6-488f-b2d9-8bcaefe3eff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "320f23446eba4e8889148aaae755ceb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the Segment and Drill class\n",
        "class Segment(BaseModel):\n",
        "    distance: int\n",
        "    instructions: str\n",
        "\n",
        "class Drill(BaseModel):\n",
        "    total_distance: int\n",
        "    total_duration: int\n",
        "    form: str\n",
        "    intensity: int\n",
        "    set_repetitions: int\n",
        "    set_distance: int\n",
        "    set_instructions: str\n",
        "    set: List[Segment]\n",
        "    rest_period: int"
      ],
      "metadata": {
        "id": "qUgTcCNqd3N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a parser\n",
        "parser = PydanticOutputParser(pydantic_object=Drill)"
      ],
      "metadata": {
        "id": "OZfpK_z6d8HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a system prompt or prompt with prompt engineering\n",
        "SYSTEM_PROMPT_TEMPLATE = \"\"\"### Task:\n",
        "You are an information extraction assistant who extracts information from a semi-structured string into a JSON dictionary format.\n",
        "\n",
        "### Input Entities:\n",
        "DRILL:\n",
        "- 'set_repitions' and 'set_distance' (e.g., 4x100, 8x150, 100, 800, ...)\n",
        "- 'set_instructions' one or more of:\n",
        "    - Ges, Arme, Beine, Tü, K, R, S, Br, Lg, S Beine, K Beine, K Arme, K Beine, RK, Lgf, Lg25, SK, BrK, Torpedo, butterfly, freestyle, CU, Reißv, LongDog, Hundepd, Entenpd, Kombi, Kontrast, DPS, EBV, AT, HB, Fb, FS, BH, Ff, Pb, SN, Brett, PT, Kanal, PK\n",
        "- A SET (below)\n",
        "- 'training_form' (A, B, G, T) and 'intensity' (1-4) (e.g., 1, 2, T2, A1, ...)\n",
        "- 'total_distance' in meters\n",
        "- 'total_duration' in minutes\n",
        "\n",
        "SET:\n",
        "- List of SEGMENTS\n",
        "- 'rest_period' in seconds (e.g., P15\", P5)\n",
        "\n",
        "SEGMENTS:\n",
        "- 'instructions' one or more of:\n",
        "    - Ges, Arme, Beine, Tü, K, R, S, Br, Lg, S Beine, K Beine, K Arme, K Beine, RK, Lgf, Lg25, SK, BrK, Torpedo, butterfly, freestyle, CU, Reißv, LongDog, Hundepd, Entenpd, Kombi, Kontrast, DPS, EBV, AT, HB, Fb, FS, BH, Ff, Pb, SN, Brett, PT, Kanal, PK\n",
        "\n",
        "### Solution Structure:\n",
        "Follow this steps to extract all information into a JSON dictionary format:\n",
        "1. Identify the 'set_repetitions' and the 'set_distance'.\n",
        "- If no 'set_repetitions' is given, 'set_repetitions' defaults to 1.\n",
        "2. Identify if there is are optional 'set_instructions' following the 'set_repitions' and the 'set_distance'.\n",
        "- If no 'set_instructions' is given, 'set_instructions' defaults to \"\".\n",
        "3. Identify one or more SEGMENTS. To identify every SEGMENT repeat step a) and b):\n",
        "    a) Identify one obligatory 'distance' in meters for the SEGMENT.\n",
        "    - This is always an indicator for a new SEGMENT!\n",
        "    b) Identify one ore more 'instructions' that are in the SEGMENT.\n",
        "    - Every text following the 'distance' belongs to the 'instructions' of this SEGMENT until a new 'distance' in meters occurs!\n",
        "    - If a 'distance' in meters occurs, start a new SEGMENT and proceed with step a)!\n",
        "4. Identify if there is an optional 'rest_period' in seconds.\n",
        "- If no 'rest_period' is given, 'rest_period' defaults to 0.\n",
        "5. Identify the 'training_form' and the 'intensity'.\n",
        "6. Identify the 'total_distance' of the DRILL in meters.\n",
        "7. Identify the 'total_duration' of the DRILL in minutes.\n",
        "\n",
        "Wrap the output in `json` tags\\n{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "{query}\"\"\"\n",
        "\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            SYSTEM_PROMPT_TEMPLATE,\n",
        "        ),\n",
        "        (\"human\", PROMPT_TEMPLATE),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ],
      "metadata": {
        "id": "AxtDitocmj_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complete the chain\n",
        "chain = prompt | hf | parser"
      ],
      "metadata": {
        "id": "DpnN3RSreCgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the results\n",
        "exercise_strings = [\n",
        "    \"4x100: 25 butterfly, 50 torpedo, 25 freestyle; A2; 400 m; 8 min\",\n",
        "    \"4x100: 25 Torpedo 50 Tü 25 DPS P15; B3; 400 m; 8 min\",\n",
        "    \"4x100: 25 Senso 50 Kontrast 25 DPS; T1; 400 m; 8 min\",\n",
        "    \"500: 25 Hundepd 25 KA BrB 25 Kontrast 25 K Faust; T2; 500 m; 9 min\",\n",
        "    \"4x150: 50 Torpedo 50 RA SB 50 K DPS P15\\\"; T2; 600 m; 12 min\",\n",
        "    \"4x300 Fb: 100 K CU 100 R Ges 100 K Ges P20\\\"; 2; 1200 m; 20 min\"\n",
        "]\n",
        "\n",
        "for i in range(len(exercise_strings)):\n",
        "    prompt = exercise_strings[i]\n",
        "    set_seed(1)\n",
        "    pydantic_response = chain.invoke({\"query\": prompt})\n",
        "    print(pydantic_response.model_dump_json(indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkSMj3bxduNT",
        "outputId": "82e2ff9d-5b56-4900-cc79-f6400ef4c689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"total_distance\": 400,\n",
            "    \"total_duration\": 8,\n",
            "    \"form\": \"A\",\n",
            "    \"intensity\": 2,\n",
            "    \"set_repetitions\": 4,\n",
            "    \"set_distance\": 100,\n",
            "    \"set_instructions\": \"25 butterfly, 50 torpedo, 25 freestyle\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"butterfly\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"torpedo\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"freestyle\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 0\n",
            "}\n",
            "{\n",
            "    \"total_distance\": 400,\n",
            "    \"total_duration\": 8,\n",
            "    \"form\": \"B\",\n",
            "    \"intensity\": 3,\n",
            "    \"set_repetitions\": 4,\n",
            "    \"set_distance\": 100,\n",
            "    \"set_instructions\": \"25 Torpedo 50 Tü 25 DPS\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"Torpedo\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"Tü\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"DPS\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 15\n",
            "}\n",
            "{\n",
            "    \"total_distance\": 400,\n",
            "    \"total_duration\": 8,\n",
            "    \"form\": \"T\",\n",
            "    \"intensity\": 1,\n",
            "    \"set_repetitions\": 4,\n",
            "    \"set_distance\": 100,\n",
            "    \"set_instructions\": \"25 Senso 50 Kontrast 25 DPS\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"Senso\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"Kontrast\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"DPS\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 0\n",
            "}\n",
            "{\n",
            "    \"total_distance\": 500,\n",
            "    \"total_duration\": 9,\n",
            "    \"form\": \"T\",\n",
            "    \"intensity\": 2,\n",
            "    \"set_repetitions\": 2,\n",
            "    \"set_distance\": 25,\n",
            "    \"set_instructions\": \"Hundepd\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"Hundepd\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"KA BrB\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"Kontrast\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 25,\n",
            "            \"instructions\": \"K Faust\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 0\n",
            "}\n",
            "{\n",
            "    \"total_distance\": 600,\n",
            "    \"total_duration\": 12,\n",
            "    \"form\": \"T\",\n",
            "    \"intensity\": 2,\n",
            "    \"set_repetitions\": 4,\n",
            "    \"set_distance\": 150,\n",
            "    \"set_instructions\": \"50 Torpedo 50 RA SB 50 K DPS\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"Torpedo\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"RA SB\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 50,\n",
            "            \"instructions\": \"K DPS\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 15\n",
            "}\n",
            "{\n",
            "    \"total_distance\": 1200,\n",
            "    \"total_duration\": 20,\n",
            "    \"form\": \"2\",\n",
            "    \"intensity\": 1,\n",
            "    \"set_repetitions\": 4,\n",
            "    \"set_distance\": 300,\n",
            "    \"set_instructions\": \"Fc: 100 K CU 100 R Ges 100 K Ges\",\n",
            "    \"set\": [\n",
            "        {\n",
            "            \"distance\": 100,\n",
            "            \"instructions\": \"K CU\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 100,\n",
            "            \"instructions\": \"R Ges\"\n",
            "        },\n",
            "        {\n",
            "            \"distance\": 100,\n",
            "            \"instructions\": \"K Ges\"\n",
            "        }\n",
            "    ],\n",
            "    \"rest_period\": 20\n",
            "}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aml4ta",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "320f23446eba4e8889148aaae755ceb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825bedb8681f4c0f8e6f9f3bf6e23732",
              "IPY_MODEL_46006bd3b9d34be48a6277d27c1d21a2",
              "IPY_MODEL_077894f810a44206ae6165318fcbad9b"
            ],
            "layout": "IPY_MODEL_8e2924c80e5e41d8b13eb7c94e8a33a5"
          }
        },
        "825bedb8681f4c0f8e6f9f3bf6e23732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364616f1ffb944238c97fb5a58ddfa6b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c9b3ec072e9476295b7c46a232a913f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "46006bd3b9d34be48a6277d27c1d21a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39a57db8e76c4dc38211270d8914005a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3e840ce149a4c0b873c8698a8efc410",
            "value": 4
          }
        },
        "077894f810a44206ae6165318fcbad9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b2b7c67e7864b058b2853615f01d111",
            "placeholder": "​",
            "style": "IPY_MODEL_625ad29ae9884d38a5b2809d296bcc4b",
            "value": " 4/4 [00:10&lt;00:00,  2.46s/it]"
          }
        },
        "8e2924c80e5e41d8b13eb7c94e8a33a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364616f1ffb944238c97fb5a58ddfa6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9b3ec072e9476295b7c46a232a913f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a57db8e76c4dc38211270d8914005a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3e840ce149a4c0b873c8698a8efc410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b2b7c67e7864b058b2853615f01d111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "625ad29ae9884d38a5b2809d296bcc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}