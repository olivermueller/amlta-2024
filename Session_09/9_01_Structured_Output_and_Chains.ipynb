{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAu-kSJo_wBW"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkW_65l0_wBX"
      },
      "source": [
        "# <font color=\"#003660\">Session 9: LLM-based Apps with LangChain</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2TLZqw4_wBX"
      },
      "source": [
        "# <font color=\"#003660\">Structured Outputs and Chains</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
        "        ... will know how to implement structured outputs in LLMs. <br>\n",
        "        ... will know how apply this to solve a real-world task in LangChain.\n",
        "    </font>\n",
        "</div>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jCXZI28fEN0"
      },
      "source": [
        "The following content is heavily inspired by the following excellent sources:\n",
        "\n",
        "* [LangChain Academy](https://academy.langchain.com/)\n",
        "* [LangChain Docs (Python)](https://python.langchain.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb8FCaO3fEN0"
      },
      "outputs": [],
      "source": [
        "!pip install -U pymupdf4llm datasets transformers accelerate bitsandbytes langchain langchain-community langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ceIegjtfEN0"
      },
      "source": [
        "# Computer Scientists and JSON: A Love Story Written in Brackets\n",
        "\n",
        "[JSON (JavaScript Object Notation)](https://www.json.org/json-en.html) is usually loved and hated by computer scientists. But this format is especially important in the online applications and databases such as [MongoDB](https://www.mongodb.com/de-de). Therefore, LLMs are often applied to extract JSON notation from unstructured text [Liu et al. (2024)](https://doi.org/10.1145/3613905.3650756).\n",
        "\n",
        "Let's try this by prompting the model as we learned it in Session 06."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DDqf0AsEBqn"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, set_seed\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"mps:0\" if torch.mps.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the a model directly in HuggingFace we can simply use the HuggingFace [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)."
      ],
      "metadata": {
        "id": "1Ei2CjINXJzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sTx1W9OnjTr"
      },
      "outputs": [],
      "source": [
        "# generate a LangChain pipeline\n",
        "LLM_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    return_full_text=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the `pipe` cannot work easily with the LangChain `invoke` command, we need to use the LangChain `HuggingFacePipeline` wrapper."
      ],
      "metadata": {
        "id": "wxC8PV0OXaxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "Kc5_GTB5XZ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us add a simple structure prompt for the JSON-format."
      ],
      "metadata": {
        "id": "zoilryf3XuGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4o7TduFfEN1"
      },
      "outputs": [],
      "source": [
        "INSTRUCTION = \"\"\"\n",
        "Use the following json format for the answer:\n",
        "{\n",
        "    \"setup\":\"<The setup of your joke>\",\n",
        "    \"punchline\":\"<The punchline to your joke>\",\n",
        "    \"rating\":\"<Optional rating of how funny your joke is, from 1 to 10>\"\n",
        "}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us generate a Joke about cats (yes, I could`nt get a better example), because we want to store it in a MongoDB."
      ],
      "metadata": {
        "id": "vNf9XAayX3vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNabAbrTfEN1"
      },
      "outputs": [],
      "source": [
        "set_seed(1)\n",
        "prompt = \"Tell me a joke about cats\"\n",
        "hopefully_json_response = hf.invoke(prompt + INSTRUCTION)\n",
        "print(hopefully_json_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good (not really funny) but will need some postprocessing to get only the JSON. Possibly we could do fine-tuning to improve that [Escarda-Fern√°ndez et al. (2024)](https://ceur-ws.org/Vol-3729/d3_rev.pdf), but usually we want to run this out of the box.\n",
        "\n",
        "A simple way to do this are [OutputParsers](https://python.langchain.com/docs/how_to/#output-parsers). In our case we will use the [`PyDanticOutputParser`](https://python.langchain.com/docs/how_to/output_parser_structured/), as it can also output dictionary formats for python."
      ],
      "metadata": {
        "id": "_DhEZBG7YIog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the PyDantic Model\n",
        "class Joke(BaseModel):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: str = Field(description=\"The setup of the joke\")\n",
        "    punchline: str = Field(description=\"The punchline to the joke\")\n",
        "    rating: Optional[int] = Field(\n",
        "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EcwV-r6zaw2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a parser\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)"
      ],
      "metadata": {
        "id": "K8p_wMY4a0gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlo7cKBjfEN1"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain\n",
        "chain = prompt | hf | parser"
      ],
      "metadata": {
        "id": "u0y7GMpMa7fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYR3JUAKfEN1"
      },
      "outputs": [],
      "source": [
        "set_seed(1)\n",
        "prompt = \"Tell me a joke about cats\"\n",
        "pydantic_response = chain.invoke({\"query\": prompt})\n",
        "print(pydantic_response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pydantic_response.model_dump(), type(pydantic_response.model_dump()))\n",
        "print(pydantic_response.model_dump_json(), type(pydantic_response.model_dump_json()))"
      ],
      "metadata": {
        "id": "jx7lTrz-hRGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "tdOpM4Sprfa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Task"
      ],
      "metadata": {
        "id": "7inUJqKfn-91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise Description:**\n",
        "\n",
        "You are tasked with creating a system that extracts structured information from semi-structured text data describing swim training drills. Your goal is to transform the input into a structured JSON dictionary format that adheres to a predefined schema. This exercise requires you to design a system prompt for an AI model and implement Python classes using Pydantic to validate the extracted data.\n",
        "\n",
        "### Requirements:\n",
        "\n",
        "1. **System Prompt Design**:\n",
        "   - Design a system prompt for an AI model that clearly explains the task of extracting swim training data.\n",
        "   - Ensure the prompt outlines how to identify key components in the input data and map them to a structured JSON format.\n",
        "\n",
        "2. **Key Input Entities to Extract**:\n",
        "   - **Drill-Level Information**:\n",
        "     - `set_repetitions` (e.g., 4x, 8x, default to 1 if absent)\n",
        "     - `set_distance` (e.g., 100, 200, ...)\n",
        "     - `set_instructions` (a combination of specific swim styles and techniques, default to `\"\"` if absent)\n",
        "     - `form` (e.g., A, B, G, T)\n",
        "     - `intensity` (e.g., 1-4)\n",
        "     - `total_distance` (total meters)\n",
        "     - `total_duration` (total minutes)\n",
        "     - An optional `rest_period` in seconds (default to 0 if absent)\n",
        "   - **Set-Level Information**:\n",
        "     - A collection of **Segments** with:\n",
        "       - `distance` in meters\n",
        "       - `instructions` Ges, Arme, Beine, T√º, K, R, S, Br, Lg, S Beine, K Beine, K Arme, K Beine, RK, Lgf, Lg25, SK, BrK, Torpedo, butterfly, freestyle, CU, Rei√üv, LongDog, Hundepd, Entenpd, Kombi, Kontrast, DPS, EBV, AT, HB, Fb, FS, BH, Ff, Pb, SN, Brett, PT, Kanal, PK\n",
        "\n",
        "     \n",
        "3. **Output Structure**:\n",
        "   - Use a JSON dictionary format for the output, ensuring it aligns with the predefined schema.\n",
        "\n",
        "4. **Implementation with Pydantic**:\n",
        "   - Implement two classes:\n",
        "     - **Segment**: Represents a single segment of the drill, including the distance and instructions.\n",
        "     - **Drill**: Represents the overall drill, containing metadata and a list of segments.\n",
        "\n",
        "5. **Task Deliverables**:\n",
        "   - Develop a clear and concise system prompt that can instruct an AI assistant to extract the required entities from semi-structured text input.\n",
        "   - Implement the **Segment** and **Drill** classes using Pydantic to validate the extracted data."
      ],
      "metadata": {
        "id": "Xz9608tft3q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`\"4x100 FB: 25 butterfly, 50 torpedo, 25 freestyle; A2; 400 m; 8 min\"`\n",
        "\n",
        "should be processed to\n",
        "\n",
        "```\n",
        "{\n",
        "    \"total_distance\": 400,\n",
        "    \"total_duration\": 8,\n",
        "    \"form\": \"A\",\n",
        "    \"intensity\": 2,\n",
        "    \"set_repetitions\": 4,\n",
        "    \"set_distance\": 100,\n",
        "    \"set_instructions\": \"FB\",\n",
        "    \"set\": [\n",
        "        {\n",
        "            \"distance\": 25,\n",
        "            \"instructions\": \"butterfly\"\n",
        "        },\n",
        "        {\n",
        "            \"distance\": 50,\n",
        "            \"instructions\": \"torpedo\"\n",
        "        },\n",
        "        {\n",
        "            \"distance\": 25,\n",
        "            \"instructions\": \"freestyle\"\n",
        "        }\n",
        "    ],\n",
        "    \"rest_period\": 0\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DHcfCMOHvPOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packages\n",
        "import os\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, set_seed\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"mps:0\" if torch.mps.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "KUaprw7IcK-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a LangChain pipeline\n",
        "LLM_NAME = \"Qwen/Qwen2.5-7B-Instruct\" # you will need a 7B model here.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    LLM_NAME\n",
        ")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    LLM_NAME,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    return_full_text=False,\n",
        ")\n",
        "\n",
        "hf = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "yCA2F1bFcXlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the Segment and Drill class\n",
        "class Segment(BaseModel):\n",
        "    # ToDo: Implement\n",
        "    pass\n",
        "\n",
        "class Drill(BaseModel):\n",
        "    # ToDo: Implement\n",
        "    pass"
      ],
      "metadata": {
        "id": "qUgTcCNqd3N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a parser\n",
        "parser = PydanticOutputParser(pydantic_object=Drill)"
      ],
      "metadata": {
        "id": "OZfpK_z6d8HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a system prompt or prompt with prompt engineering\n",
        "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
        "YOUR SYSTEM PROMPT HERE (Optional based on the Prompting Method, if you want the standard system prompt use: You are an assistant that extracts JSON from a semi-structured language input about swim training.)\n",
        "Do not delete the part below.\n",
        "Wrap the output in `json` tags\\n{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "YOUR PROMPT HERE (Optional based on the Prompting Method.)\n",
        "{query}\"\"\"\n",
        "\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            SYSTEM_PROMPT_TEMPLATE,\n",
        "        ),\n",
        "        (\"human\", PROMPT_TEMPLATE),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ],
      "metadata": {
        "id": "AxtDitocmj_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complete the chain\n",
        "chain = prompt | hf | parser"
      ],
      "metadata": {
        "id": "DpnN3RSreCgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the results\n",
        "exercise_strings = [\n",
        "    \"4x100: 25 butterfly, 50 torpedo, 25 freestyle; A2; 400 m; 8 min\",\n",
        "    \"4x100: 25 Torpedo 50 T√º 25 DPS P15; B3; 400 m; 8 min\",\n",
        "    \"4x100: 25 Senso 50 Kontrast 25 DPS; T1; 400 m; 8 min\",\n",
        "    \"500: 25 Hundepd 25 KA BrB 25 Kontrast 25 K Faust; T2; 500 m; 9 min\",\n",
        "    \"4x150: 50 Torpedo 50 RA SB 50 K DPS P15\\\"; T2; 600 m; 12 min\",\n",
        "    \"4x300 Fb: 100 K CU 100 R Ges 100 K Ges P20\\\"; 2; 1200 m; 20 min\"\n",
        "]\n",
        "\n",
        "for i in range(len(exercise_strings)):\n",
        "    prompt = exercise_strings[i]\n",
        "    set_seed(1)\n",
        "    pydantic_response = chain.invoke({\"query\": prompt})\n",
        "    print(pydantic_response.model_dump_json(indent=4))"
      ],
      "metadata": {
        "id": "ZkSMj3bxduNT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aml4ta",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}