{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "DAu-kSJo_wBW",
      "metadata": {
        "id": "DAu-kSJo_wBW"
      },
      "source": [
        "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BkW_65l0_wBX",
      "metadata": {
        "id": "BkW_65l0_wBX"
      },
      "source": [
        "# <font color=\"#003660\">Session 9: LLM-based Apps with LangChain</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O2TLZqw4_wBX",
      "metadata": {
        "id": "O2TLZqw4_wBX"
      },
      "source": [
        "# <font color=\"#003660\">LLM Agents</font>\n",
        "\n",
        "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
        "\n",
        "<p>\n",
        "\n",
        "<div>\n",
        "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
        "        ... will know how to implement structured outputs in LLMs. <br>\n",
        "        ... will know how apply this to solve a real-world task in LangChain.\n",
        "    </font>\n",
        "</div>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8jCXZI28fEN0",
      "metadata": {
        "id": "8jCXZI28fEN0"
      },
      "source": [
        "The following content is heavily inspired by the following excellent sources:\n",
        "\n",
        "* [LangChain Academy](https://academy.langchain.com/)\n",
        "* [Introduction to LangChain Agents](https://github.com/langchain-ai/langchain-academy/blob/main/module-1/agent.ipynb)\n",
        "* [LangChain Docs (Python)](https://python.langchain.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wb8FCaO3fEN0",
      "metadata": {
        "id": "Wb8FCaO3fEN0"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-community langchain-ollama langgraph colab-xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f5e36a-da49-4ae2-8c74-b910a2f992fc",
      "metadata": {
        "id": "98f5e36a-da49-4ae2-8c74-b910a2f992fc"
      },
      "source": [
        "# Agent\n",
        "\n",
        "We want to build an Agent that consists a router (graph).\n",
        "\n",
        "* The chat model will decide to make a tool call or not based upon the user input\n",
        "* A conditional edge routes to a node that calls our tool or simply ends the route with an end node\n",
        "* If multiple tool calls are necessary as in a mathematical environment where we want to apply multiple additions, subtractions, multiplications or divisions, the model needs a route to jump back and call the tools again.\n",
        "\n",
        "We can solve this by simply pass that `ToolMessage` *back to the model*?\n",
        "\n",
        "We can let it either (1) call another tool or (2) respond directly.\n",
        "\n",
        "This is the intuition behind [*Reason+Act (ReAct)*](https://doi.org/10.48550/arXiv.2210.03629), a general agent architecture.\n",
        "  \n",
        "* `reason` - let the model reason about the input (e.g., call a tool or just respond directly)\n",
        "* `act` - let the model call specific tools\n",
        "* `observe` - pass the tool output back to the model\n",
        "\n",
        "* (`answer` - answer the question after iterations of reason-act-observe)\n",
        "\n",
        "\n",
        "This [general purpose architecture](https://blog.langchain.dev/planning-for-agents/) can be applied to many types of tools.\n",
        "\n",
        "![Screenshot 2024-08-21 at 12.45.43 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbac0b4a2c1e5e02f3e78b_agent2.png)\n",
        "\n",
        "[Source: LangChain Academy GitHub](https://github.com/langchain-ai/langchain-academy/blob/main/module-1/agent.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GiYkUT1Dtaqt",
      "metadata": {
        "id": "GiYkUT1Dtaqt"
      },
      "outputs": [],
      "source": [
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQN91atU-2Rn",
      "metadata": {
        "id": "uQN91atU-2Rn"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MyOQV_6ctt5q",
      "metadata": {
        "id": "MyOQV_6ctt5q"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nev8YZKD-9ds",
      "metadata": {
        "id": "nev8YZKD-9ds"
      },
      "outputs": [],
      "source": [
        "%xterm # Copy this command in the Xterm starting below: HOST=0.0.0.0 ollama serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sn2WuPFUtVbD",
      "metadata": {
        "id": "Sn2WuPFUtVbD"
      },
      "outputs": [],
      "source": [
        "!ollama pull qwen2.5:1.5b\n",
        "!ollama pull qwen2.5:7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325yBo7V_gWr",
      "metadata": {
        "id": "325yBo7V_gWr"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from langgraph.graph import MessagesState\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71795ff1-d6a7-448d-8b55-88bbd1ed3dbe",
      "metadata": {
        "id": "71795ff1-d6a7-448d-8b55-88bbd1ed3dbe"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Divide a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a / b\n",
        "\n",
        "@tool\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract b from a.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a - b\n",
        "\n",
        "tools = [add, subtract, multiply, divide]\n",
        "\n",
        "LLM_NAME = \"qwen2.5:7b\"\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=LLM_NAME,\n",
        "    temperature=0,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2cec014-3023-405c-be79-de8fc7adb346",
      "metadata": {
        "id": "a2cec014-3023-405c-be79-de8fc7adb346"
      },
      "source": [
        "Let's create our LLM and prompt it with the overall desired agent behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d061813f-ebc0-432c-91ec-3b42b15c30b6",
      "metadata": {
        "id": "d061813f-ebc0-432c-91ec-3b42b15c30b6"
      },
      "outputs": [],
      "source": [
        "# System message\n",
        "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9de14ViLpyg",
      "metadata": {
        "id": "N9de14ViLpyg"
      },
      "source": [
        "We will use a `MessagesState` and define a `Tools` node with our list of tools.\n",
        "\n",
        "The `Assistant` node is just our model with bound tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GpcuTnsSAFt5",
      "metadata": {
        "id": "GpcuTnsSAFt5"
      },
      "outputs": [],
      "source": [
        "# Node\n",
        "def assistant(state: MessagesState):\n",
        "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eb43343-9a6f-42cb-86e6-4380f928633c",
      "metadata": {
        "id": "4eb43343-9a6f-42cb-86e6-4380f928633c"
      },
      "source": [
        "\n",
        "\n",
        "We create a graph with `Assistant` and `Tools` nodes.\n",
        "\n",
        "We add `tools_condition` edge, which routes to `End` or to `Tools` based on  whether the `Assistant` calls a tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef13cd4-05a6-4084-a620-2e7b91d9a72f",
      "metadata": {
        "id": "aef13cd4-05a6-4084-a620-2e7b91d9a72f"
      },
      "outputs": [],
      "source": [
        "# Graph\n",
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "# Define nodes: these do the work\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
        "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
        "    tools_condition,\n",
        ")\n",
        "react_graph = builder.compile()\n",
        "\n",
        "# Show\n",
        "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_7MtDVkBNomY",
      "metadata": {
        "id": "_7MtDVkBNomY"
      },
      "outputs": [],
      "source": [
        "# Graph\n",
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "# Define nodes: these do the work\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Define edges: these determine how the control flow moves\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
        "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
        "    tools_condition,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ueHOzuEjL8MD",
      "metadata": {
        "id": "ueHOzuEjL8MD"
      },
      "source": [
        "Now, we add one new step:\n",
        "\n",
        "We connect the `Tools` node *back* to the `Assistant`, forming a loop.\n",
        "\n",
        "* After the `assistant` node executes, `tools_condition` checks if the model's output is a tool call.\n",
        "* If it is a tool call, the flow is directed to the `tools` node.\n",
        "* The `tools` node connects back to `assistant`.\n",
        "* This loop continues as long as the model decides to call tools.\n",
        "* If the model response is not a tool call, the flow is directed to END, terminating the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QKJtJkrVL66n",
      "metadata": {
        "id": "QKJtJkrVL66n"
      },
      "outputs": [],
      "source": [
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "react_graph = builder.compile()\n",
        "\n",
        "# Show\n",
        "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75602459-d8ca-47b4-9518-3f38343ebfe4",
      "metadata": {
        "id": "75602459-d8ca-47b4-9518-3f38343ebfe4"
      },
      "outputs": [],
      "source": [
        "messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2. Divide the output by 10\")]\n",
        "messages = react_graph.invoke({\"messages\": messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b517142d-c40c-48bf-a5b8-c8409427aa79",
      "metadata": {
        "id": "b517142d-c40c-48bf-a5b8-c8409427aa79"
      },
      "outputs": [],
      "source": [
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zJYCEQUGQ2Gc",
      "metadata": {
        "id": "zJYCEQUGQ2Gc"
      },
      "source": [
        "# Your Task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TO5OyXRXTmF2",
      "metadata": {
        "id": "TO5OyXRXTmF2"
      },
      "source": [
        "## Implement Admin Verification Tool and Agent\n",
        "\n",
        "You are tasked with creating a system to verify if a user is an admin based on their provided username and passphrase. Your system should utilize a **tool** and an **agent** to process and respond to user requests.\n",
        "\n",
        "#### Requirements:\n",
        "\n",
        "1. **Verification Tool**:\n",
        "   - Create a function named `verify_admin` that takes a username and passphrase as arguments and returns `True` if both are correct (`username=\"admin\"` and `passphrase=\"adminpassword\"`). Otherwise, return `False`.\n",
        "\n",
        "2. **Agent**:\n",
        "   - Implement an agent to interact with users. The agent must use the `verify_admin` tool to verify the admin credentials.\n",
        "   - The agent should respond with an appropriate message based on the verification result:\n",
        "     - If the credentials are correct, respond with: `\"Verification successful! Welcome, admin.\"`\n",
        "     - If the credentials are incorrect, respond with: `\"Verification failed. Invalid credentials.\"`\n",
        "\n",
        "3. **Messages Completion**:\n",
        "   - Complete the final messages at the end of the code to ensure that the agent can respond to two user requests:\n",
        "     - User 1: `\"Please verify me: I am the admin and my passphrase is adminpassword\"`\n",
        "     - User 2: `\"Please verify me: I am the admin and my passphrase is admin-assword\"`\n",
        "\n",
        "\n",
        "**Hint:** It is mostly copy and paste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8lM_jWQyRyST",
      "metadata": {
        "id": "8lM_jWQyRyST"
      },
      "outputs": [],
      "source": [
        "LLM_NAME = \"qwen2.5:7b\"\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=LLM_NAME,\n",
        "    temperature=0,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jx2e8wHhQ51_",
      "metadata": {
        "id": "jx2e8wHhQ51_"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def verify_admin(username: str, passphrase: str) -> bool:\n",
        "    # ToDo: implement tool\n",
        "    pass\n",
        "\n",
        "tools = [verify_admin, ]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wa0S-TowR8R5",
      "metadata": {
        "id": "wa0S-TowR8R5"
      },
      "outputs": [],
      "source": [
        "# ToDo: implement system message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jOLd9sobSJFf",
      "metadata": {
        "id": "jOLd9sobSJFf"
      },
      "outputs": [],
      "source": [
        "# ToDo: implement assistant node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Wu_Tc9pRvkE",
      "metadata": {
        "id": "6Wu_Tc9pRvkE"
      },
      "outputs": [],
      "source": [
        "# ToDo: implement graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-IOyDD7pSQoF",
      "metadata": {
        "id": "-IOyDD7pSQoF"
      },
      "outputs": [],
      "source": [
        "messages = [HumanMessage(content=\"Please verify me: I am the admin and my passphrase is adminpassword\")]\n",
        "messages = react_graph.invoke({\"messages\": messages})\n",
        "\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "No7VDsxhSlhi",
      "metadata": {
        "id": "No7VDsxhSlhi"
      },
      "outputs": [],
      "source": [
        "messages = [HumanMessage(content=\"Please verify me: I am the admin and my passphrase is admin-assword\")]\n",
        "messages = react_graph.invoke({\"messages\": messages})\n",
        "\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
